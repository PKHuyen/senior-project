{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from googleapiclient.discovery import build\n",
    "from googleapiclient.errors import HttpError\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "import os\n",
    "import json\n",
    "\n",
    "SERVICE_ACCOUNT_FILE = '../credentials.json'\n",
    "SCOPES = ['https://www.googleapis.com/auth/drive']\n",
    "flow = InstalledAppFlow.from_client_secrets_file(SERVICE_ACCOUNT_FILE, SCOPES)\n",
    "creds = flow.run_local_server(port=8502)\n",
    "service = build('drive', 'v3', credentials=creds)\n",
    "\n",
    "KEYFRAME_FOLDER_ID = '1bqJG0CRIIuVIib3pBcA2k8iiRyWlwmq9'\n",
    "\n",
    "def list_drive_files(folder_id):\n",
    "    query = f\"'{folder_id}' in parents and trashed = false\"\n",
    "    files = []\n",
    "    try:\n",
    "        results = service.files().list(q=query, fields=\"files(id, name, mimeType)\").execute()\n",
    "        files = results.get('files', [])\n",
    "    except HttpError as error:\n",
    "        print(f\"An error occurred: {error}\")\n",
    "    return files\n",
    "\n",
    "def get_image_paths(folder_id, video_ID):\n",
    "    files = list_drive_files(folder_id)\n",
    "    image_video_dict = {}\n",
    "    idx = 0\n",
    "    for file in sorted(files, key=lambda x: x['name']):\n",
    "        if file['mimeType'] == 'image/jpeg':\n",
    "            file_id = file['id']\n",
    "            img_url = f\"https://drive.google.com/uc?id={file_id}\"\n",
    "            frame_timestamp = file['name'].replace('.jpg', '')\n",
    "            image_video_dict[idx] = {'frame_path': img_url, 'video_ID': video_ID, 'timestamp': frame_timestamp}\n",
    "            idx += 1\n",
    "    return image_video_dict\n",
    "\n",
    "def save_json(data, output_folder, filename):\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    \n",
    "    file_path = os.path.join(output_folder, filename)\n",
    "    with open(file_path, 'w') as outfile:\n",
    "        json.dump(data, outfile, indent=4)\n",
    "\n",
    "def process_keyframe_folders(keyframe_folder_id, output_folder):\n",
    "    video_folders = list_drive_files(keyframe_folder_id)\n",
    "    for video_folder in video_folders:\n",
    "        if video_folder['mimeType'] == 'application/vnd.google-apps.folder': \n",
    "            video_ID = video_folder['name'] \n",
    "            video_folder_id = video_folder['id']\n",
    "\n",
    "            subfolders = list_drive_files(video_folder_id)\n",
    "            for subfolder in subfolders:\n",
    "                if '_reduced' in subfolder['name']:\n",
    "                    continue\n",
    "                \n",
    "                subfolder_id = subfolder['id']\n",
    "                image_info_dict = get_image_paths(subfolder_id, video_ID)\n",
    "                \n",
    "                filename = f\"{subfolder['name']}.json\"\n",
    "                save_json(image_info_dict, output_folder, filename)\n",
    "\n",
    "output_folder = '../keyframe_information/annotation'\n",
    "process_keyframe_folders(KEYFRAME_FOLDER_ID, output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_json_files():\n",
    "    # Dictionary to store all combined data\n",
    "    combined_data = {}\n",
    "    current_index = 0\n",
    "\n",
    "    # List all JSON files (you can also specify the path explicitly)\n",
    "    json_files = ['/Users/kietnguyen/Downloads/drive-download-20241126T062057Z-001/L00.json', '/Users/kietnguyen/Downloads/drive-download-20241126T062057Z-001/L01.json', '/Users/kietnguyen/Downloads/drive-download-20241126T062057Z-001/L02.json',\n",
    "                  '/Users/kietnguyen/Downloads/drive-download-20241126T062057Z-001/L03.json', '/Users/kietnguyen/Downloads/drive-download-20241126T062057Z-001/L05.json', '/Users/kietnguyen/Downloads/drive-download-20241126T062057Z-001/L06.json']\n",
    "\n",
    "    # Process each JSON file\n",
    "    for json_file in json_files:\n",
    "        try:\n",
    "            with open(json_file, 'r') as f:\n",
    "                data = json.load(f)\n",
    "\n",
    "                # Add each entry to combined data with a new index\n",
    "                for _, value in data.items():\n",
    "                    combined_data[str(current_index)] = value\n",
    "                    current_index += 1\n",
    "\n",
    "            print(f\"Processed {json_file}\")\n",
    "\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Warning: {json_file} not found\")\n",
    "        except json.JSONDecodeError:\n",
    "            print(f\"Warning: Error decoding {json_file}\")\n",
    "\n",
    "    # Save combined data\n",
    "    with open('combined_data.json', 'w') as f:\n",
    "        json.dump(combined_data, f, indent=4)\n",
    "\n",
    "    print(f\"\\nTotal frames processed: {current_index}\")\n",
    "    print(\"Combined data saved to 'combined_data.json'\")\n",
    "\n",
    "\n",
    "# Run the function\n",
    "combine_json_files()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
